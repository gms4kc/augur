We were able to create our own test database and insert our own data. The function APIcall makes the API call and takes the email as a parameter. This function worked successfully.

There were many issues that occured throughout this process. There was some trouble getting back into Postgres after awhile, but after remembering how to get back in that was fine. Another problem was with installing Jupyter Notebooks using pip because it needed to be pip3. Imports were also an issue because psycopg2 needed to be installed. 

We had some difficulty working with the psycopg2 library - It's a realtively simple, very powerful tool, but there's certainly a learning curve involved.  Trying to pull the json like we did in our previous prototype, and then turn that json object into a usable python object was a bit of a hurdle, as well as trying to format queries in a way that cooperated simultaneously with python, psycopg2, and postgres.  However, we pulled through and are able to query a database, call the api, and insert data back into the database iteratively.  One goal for the next sprint is to make the working code more portable, not relying on our current test database, which will take a little more SQL practice.